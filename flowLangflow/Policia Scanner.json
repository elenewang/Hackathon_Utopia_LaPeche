{"id":"a1c9c130-e1ec-4e4f-a04b-7794c2960955","data":{"nodes":[{"id":"TextOutput-HSKzn","type":"genericNode","position":{"x":774.0270738484815,"y":483.70695743038084},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as output.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Display a text output in the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextOutput","id":"TextOutput-HSKzn"},"selected":true,"width":320,"height":233,"positionAbsolute":{"x":774.0270738484815,"y":483.70695743038084},"dragging":false},{"id":"Prompt-Xndyy","type":"genericNode","position":{"x":-10.193804642907025,"y":265.33024081250704},"data":{"description":"Create a prompt template with dynamic variables.","display_name":"Prompt","id":"Prompt-Xndyy","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Eqip AI as a legal expert\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"tool_mode":false,"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"<instructions>\nPlay the role of a legal expert on privacy policy and terms and conditions. Your task is to read a privacy policy document, or the terms and conditions document given to you thoroughly.\n\nHere is the document to be read,\n\n<extracted_document>\n{EXTRACTED_DOCUMENT}\n</extracted_document>\n\n\nAfter reading the document, make sure to answer these questions and classify them as good or bad.\n<prompt_questions>\n{PROMPTS}\n</prompt_questions> \n\n\nRemember to\n- Only use JSON STRICTLY\n- Refer JSON template <template> {JSON_TEMPLATE} </template> \n-Make each point no more than 15 words.\n-Get straight to the point.\n-Use English that an 18-year-old can understand.\n</instructions>","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput","load_from_db":false},"EXTRACTED_DOCUMENT":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"EXTRACTED_DOCUMENT","display_name":"EXTRACTED_DOCUMENT","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"PROMPTS":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"PROMPTS","display_name":"PROMPTS","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"JSON_TEMPLATE":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"JSON_TEMPLATE","display_name":"JSON_TEMPLATE","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Eqip AI as a legal expert","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Legal agent prompt","documentation":"","custom_fields":{"template":["EXTRACTED_DOCUMENT","PROMPTS","JSON_TEMPLATE"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true,"required_inputs":null}],"field_order":["template"],"beta":false,"legacy":false,"error":null,"edited":true,"metadata":{},"tool_mode":false},"type":"Prompt"},"selected":false,"width":320,"height":498,"positionAbsolute":{"x":-10.193804642907025,"y":265.33024081250704},"dragging":false},{"id":"MistralModel-4LAWL","type":"genericNode","position":{"x":386.05175323341655,"y":132.82787165318143},"data":{"node":{"template":{"_type":"Component","output_parser":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"output_parser","value":"","display_name":"Output Parser","advanced":true,"input_types":["OutputParser"],"dynamic":false,"info":"The parser to use to parse the output of the model","title_case":false,"type":"other","_input_type":"HandleInput"},"api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"qvIu8ixINKHe1rTDGzciQveNJcFQsJQp","display_name":"Mistral API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The Mistral API Key to use for the Mistral model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_mistralai import ChatMistralAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\n\n\nclass MistralAIModelComponent(LCModelComponent):\n    display_name = \"MistralAI\"\n    description = \"Generates text using MistralAI LLMs.\"\n    icon = \"MistralAI\"\n    name = \"MistralModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"open-mixtral-8x7b\",\n                \"open-mixtral-8x22b\",\n                \"mistral-small-latest\",\n                \"mistral-medium-latest\",\n                \"mistral-large-latest\",\n                \"codestral-latest\",\n            ],\n            value=\"codestral-latest\",\n        ),\n        StrInput(\n            name=\"mistral_api_base\",\n            display_name=\"Mistral API Base\",\n            advanced=True,\n            info=\"The base URL of the Mistral API. Defaults to https://api.mistral.ai/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Mistral API Key\",\n            info=\"The Mistral API Key to use for the Mistral model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", advanced=False, value=0.5),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", advanced=True, value=5),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", advanced=True, value=60),\n        IntInput(name=\"max_concurrent_requests\", display_name=\"Max Concurrent Requests\", advanced=True, value=3),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", advanced=True, value=1),\n        IntInput(name=\"random_seed\", display_name=\"Random Seed\", value=1, advanced=True),\n        BoolInput(name=\"safe_mode\", display_name=\"Safe Mode\", advanced=True),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        mistral_api_key = self.api_key\n        temperature = self.temperature\n        model_name = self.model_name\n        max_tokens = self.max_tokens\n        mistral_api_base = self.mistral_api_base or \"https://api.mistral.ai/v1\"\n        max_retries = self.max_retries\n        timeout = self.timeout\n        max_concurrent_requests = self.max_concurrent_requests\n        top_p = self.top_p\n        random_seed = self.random_seed\n        safe_mode = self.safe_mode\n\n        api_key = SecretStr(mistral_api_key).get_secret_value() if mistral_api_key else None\n\n        return ChatMistralAI(\n            max_tokens=max_tokens or None,\n            model_name=model_name,\n            endpoint=mistral_api_base,\n            api_key=api_key,\n            temperature=temperature,\n            max_retries=max_retries,\n            timeout=timeout,\n            max_concurrent_requests=max_concurrent_requests,\n            top_p=top_p,\n            random_seed=random_seed,\n            safe_mode=safe_mode,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"max_concurrent_requests":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_concurrent_requests","value":3,"display_name":"Max Concurrent Requests","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"max_retries":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_retries","value":5,"display_name":"Max Retries","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"mistral_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"mistral_api_base","value":"","display_name":"Mistral API Base","advanced":true,"dynamic":false,"info":"The base URL of the Mistral API. Defaults to https://api.mistral.ai/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"model_name":{"tool_mode":false,"trace_as_metadata":true,"options":["open-mixtral-8x7b","open-mixtral-8x22b","mistral-small-latest","mistral-medium-latest","mistral-large-latest","codestral-latest"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"open-mixtral-8x22b","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"random_seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"random_seed","value":1,"display_name":"Random Seed","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"safe_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"safe_mode","value":false,"display_name":"Safe Mode","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":false,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.3,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"},"timeout":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"timeout","value":60,"display_name":"Timeout","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int","_input_type":"IntInput"},"top_p":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"top_p","value":1,"display_name":"Top P","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using MistralAI LLMs.","icon":"MistralAI","base_classes":["LanguageModel","Message"],"display_name":"MistralAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"required_inputs":[]},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true,"required_inputs":[]}],"field_order":["input_value","system_message","stream","max_tokens","model_name","mistral_api_base","api_key","temperature","max_retries","timeout","max_concurrent_requests","top_p","random_seed","safe_mode","output_parser"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"MistralModel","id":"MistralModel-4LAWL"},"selected":false,"width":320,"height":672,"positionAbsolute":{"x":386.05175323341655,"y":132.82787165318143},"dragging":false},{"id":"SubFlow-lQZFx","type":"genericNode","position":{"x":-837.72466991752,"y":637.8625232487819},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any\n\nfrom loguru import logger\n\nfrom langflow.base.flow_processing.utils import build_data_from_result_data\nfrom langflow.custom import Component\nfrom langflow.graph.graph.base import Graph\nfrom langflow.graph.vertex.base import Vertex\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.io import DropdownInput, Output\nfrom langflow.schema import Data, dotdict\n\n\nclass SubFlowComponent(Component):\n    display_name = \"Sub Flow\"\n    description = \"Generates a Component from a Flow, with all of its inputs, and \"\n    name = \"SubFlow\"\n    beta: bool = True\n    icon = \"Workflow\"\n\n    def get_flow_names(self) -> list[str]:\n        flow_data = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_data]\n\n    def get_flow(self, flow_name: str) -> Data | None:\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        for key in list(build_config.keys()):\n            if key not in [x.name for x in self.inputs] + [\"code\", \"_type\", \"get_final_results_only\"]:\n                del build_config[key]\n        if field_value is not None and field_name == \"flow_name\":\n            try:\n                flow_data = self.get_flow(field_value)\n            except Exception:  # noqa: BLE001\n                logger.exception(f\"Error getting flow {field_value}\")\n            else:\n                if not flow_data:\n                    msg = f\"Flow {field_value} not found.\"\n                    logger.error(msg)\n                else:\n                    try:\n                        graph = Graph.from_payload(flow_data.data[\"data\"])\n                        # Get all inputs from the graph\n                        inputs = get_flow_inputs(graph)\n                        # Add inputs to the build config\n                        build_config = self.add_inputs_to_build_config(inputs, build_config)\n                    except Exception:  # noqa: BLE001\n                        logger.exception(f\"Error building graph for flow {field_value}\")\n\n        return build_config\n\n    def add_inputs_to_build_config(self, inputs_vertex: list[Vertex], build_config: dotdict):\n        new_fields: list[dotdict] = []\n\n        for vertex in inputs_vertex:\n            new_vertex_inputs = []\n            field_template = vertex.data[\"node\"][\"template\"]\n            for inp in field_template:\n                if inp not in {\"code\", \"_type\"}:\n                    field_template[inp][\"display_name\"] = (\n                        vertex.display_name + \" - \" + field_template[inp][\"display_name\"]\n                    )\n                    field_template[inp][\"name\"] = vertex.id + \"|\" + inp\n                    new_vertex_inputs.append(field_template[inp])\n            new_fields += new_vertex_inputs\n        for field in new_fields:\n            build_config[field[\"name\"]] = field\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\",\n            display_name=\"Flow Name\",\n            info=\"The name of the flow to run.\",\n            options=[],\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"flow_outputs\", display_name=\"Flow Outputs\", method=\"generate_results\")]\n\n    async def generate_results(self) -> list[Data]:\n        tweaks: dict = {}\n        for field in self._attributes:\n            if field != \"flow_name\" and \"|\" in field:\n                [node, name] = field.split(\"|\")\n                if node not in tweaks:\n                    tweaks[node] = {}\n                tweaks[node][name] = self._attributes[field]\n        flow_name = self._attributes.get(\"flow_name\")\n        run_outputs = await self.run_flow(\n            tweaks=tweaks,\n            flow_name=flow_name,\n            output_type=\"all\",\n        )\n        data: list[Data] = []\n        if not run_outputs:\n            return data\n        run_output = run_outputs[0]\n\n        if run_output is not None:\n            for output in run_output.outputs:\n                if output:\n                    data.extend(build_data_from_result_data(output))\n        return data\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"flow_name":{"tool_mode":false,"trace_as_metadata":true,"options":["Document Q&A","Basic Prompting","PolicyScannerFlow","Custom Component Generator","Research Agent","Policia Scanner","Prompt Classifier"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"flow_name","value":"Prompt Classifier","display_name":"Flow Name","advanced":false,"dynamic":false,"info":"The name of the flow to run.","real_time_refresh":true,"refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput"},"TextInput-ghjCa|input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"TextInput-ghjCa|input_value","value":"https://secure.booking.com/","display_name":"Text Input - Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Generates a Component from a Flow, with all of its inputs, and ","icon":"Workflow","base_classes":["Data"],"display_name":"Sub Flow","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"flow_outputs","hidden":null,"display_name":"Flow Outputs","method":"generate_results","value":"__UNDEFINED__","cache":true,"required_inputs":null}],"field_order":["flow_name"],"beta":true,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"SubFlow","id":"SubFlow-lQZFx"},"selected":false,"width":320,"height":339,"positionAbsolute":{"x":-837.72466991752,"y":637.8625232487819},"dragging":false},{"id":"ParseData-nPda4","type":"genericNode","position":{"x":-402.8310726739693,"y":676.3435013298915},"data":{"node":{"template":{"_type":"Component","data":{"tool_mode":false,"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"{text}","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"ParseData","id":"ParseData-nPda4"},"selected":false,"width":320,"height":302,"positionAbsolute":{"x":-402.8310726739693,"y":676.3435013298915},"dragging":false},{"id":"TextInput-Gravr","type":"genericNode","position":{"x":-1254.4122083400089,"y":693.0944929090033},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value_b\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value_b,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value_b":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value_b","value":"https://secure.booking.com/","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value_b"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextInput","id":"TextInput-Gravr"},"selected":false,"width":320,"height":233,"positionAbsolute":{"x":-1254.4122083400089,"y":693.0944929090033},"dragging":false},{"id":"TextInput-1P6QD","type":"genericNode","position":{"x":-428.5430863204442,"y":309.59502668520435},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"{\n  \"Title\": \"{{Domain of the company}}\",\n  \"Results\": {\n    \"[Good]\": [\n....\n    ],\n    \"[Bad]\": [\n...\n    ],\n    \"[GDPR]\": \"{{GDPR_Compliance}}\"\n  }\n}","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":false,"lf_version":"1.1.0"},"type":"TextInput","id":"TextInput-1P6QD"},"selected":false,"width":320,"height":233,"dragging":false,"positionAbsolute":{"x":-428.5430863204442,"y":309.59502668520435}},{"id":"TextInput-740VY","type":"genericNode","position":{"x":-406.3014190885603,"y":-21.191077795466185},"data":{"node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Scanned policy\"\n    description = \"Extracted document from webpage.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Policy agreement to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Policy agreement to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Extracted document from webpage.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"legacy":false,"edited":true,"metadata":{},"tool_mode":false},"type":"TextInput","id":"TextInput-740VY"},"selected":false,"width":320,"height":233,"dragging":false,"positionAbsolute":{"x":-406.3014190885603,"y":-21.191077795466185}}],"edges":[{"source":"Prompt-Xndyy","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-Xndyyœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"MistralModel-4LAWL","targetHandle":"{œfieldNameœ:œsystem_messageœ,œidœ:œMistralModel-4LAWLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"system_message","id":"MistralModel-4LAWL","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-Xndyy","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-Xndyy{œdataTypeœ:œPromptœ,œidœ:œPrompt-Xndyyœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-MistralModel-4LAWL{œfieldNameœ:œsystem_messageœ,œidœ:œMistralModel-4LAWLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"SubFlow-lQZFx","sourceHandle":"{œdataTypeœ:œSubFlowœ,œidœ:œSubFlow-lQZFxœ,œnameœ:œflow_outputsœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-nPda4","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-nPda4œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-nPda4","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"SubFlow","id":"SubFlow-lQZFx","name":"flow_outputs","output_types":["Data"]}},"id":"reactflow__edge-SubFlow-lQZFx{œdataTypeœ:œSubFlowœ,œidœ:œSubFlow-lQZFxœ,œnameœ:œflow_outputsœ,œoutput_typesœ:[œDataœ]}-ParseData-nPda4{œfieldNameœ:œdataœ,œidœ:œParseData-nPda4œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","animated":false,"className":""},{"source":"TextInput-Gravr","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-Gravrœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"SubFlow-lQZFx","targetHandle":"{œfieldNameœ:œTextInput-ghjCa|input_valueœ,œidœ:œSubFlow-lQZFxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"TextInput-ghjCa|input_value","id":"SubFlow-lQZFx","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-Gravr","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-Gravr{œdataTypeœ:œTextInputœ,œidœ:œTextInput-Gravrœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-SubFlow-lQZFx{œfieldNameœ:œTextInput-ghjCa|input_valueœ,œidœ:œSubFlow-lQZFxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"ParseData-nPda4","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-nPda4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-Xndyy","targetHandle":"{œfieldNameœ:œPROMPTSœ,œidœ:œPrompt-Xndyyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"PROMPTS","id":"Prompt-Xndyy","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-nPda4","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-nPda4{œdataTypeœ:œParseDataœ,œidœ:œParseData-nPda4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-Xndyy{œfieldNameœ:œPROMPTSœ,œidœ:œPrompt-Xndyyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"TextInput-1P6QD","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-1P6QDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-Xndyy","targetHandle":"{œfieldNameœ:œJSON_TEMPLATEœ,œidœ:œPrompt-Xndyyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"JSON_TEMPLATE","id":"Prompt-Xndyy","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-1P6QD","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-1P6QD{œdataTypeœ:œTextInputœ,œidœ:œTextInput-1P6QDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-Xndyy{œfieldNameœ:œJSON_TEMPLATEœ,œidœ:œPrompt-Xndyyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"MistralModel-4LAWL","sourceHandle":"{œdataTypeœ:œMistralModelœ,œidœ:œMistralModel-4LAWLœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"TextOutput-HSKzn","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-HSKznœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-HSKzn","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"MistralModel","id":"MistralModel-4LAWL","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-MistralModel-4LAWL{œdataTypeœ:œMistralModelœ,œidœ:œMistralModel-4LAWLœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-HSKzn{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-HSKznœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","animated":false,"className":""},{"source":"TextInput-740VY","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-740VYœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-Xndyy","targetHandle":"{œfieldNameœ:œEXTRACTED_DOCUMENTœ,œidœ:œPrompt-Xndyyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"EXTRACTED_DOCUMENT","id":"Prompt-Xndyy","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-740VY","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-740VY{œdataTypeœ:œTextInputœ,œidœ:œTextInput-740VYœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-Xndyy{œfieldNameœ:œEXTRACTED_DOCUMENTœ,œidœ:œPrompt-Xndyyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""}],"viewport":{"x":689.3073408783399,"y":111.82107320268074,"zoom":0.46522192965845843}},"description":"A scanner for web-scrapped data that reveals consumer insights","name":"Policia Scanner","last_tested_version":"1.1.0","endpoint_name":null,"is_component":false}